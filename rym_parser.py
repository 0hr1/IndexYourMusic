
# =====================================
# Imports
# =====================================

from rym_browser import RymBrowser
from rym_page import CollectionPage, ReleasePage
from release import ReleaseData, ReleaseDataSaver
from bs4 import BeautifulSoup
from numpy import arange
from tqdm import tqdm
from random import randint
from os import path
import dataclasses
import json
import time
import typing

# =====================================
# Classes
# =====================================

class RymParser():
    """! 
    @brief  Class for parsing a users collection and saving release data
    """

    COLLECTION_PAGE_URL = "https://rateyourmusic.com/collection/{}/r{}/{}" # user, min rating, page
    RATING_STEP = 0.5

    def __init__(self, user: str, start_rating: float =0.5, end_rating: float =5.0, output_path: str="data"):
        self._browser = RymBrowser()

        self._username = self._browser.get_case_sensitive_username(user)
        self._start_rating = start_rating
        self._end_rating = end_rating
        self._db_output_file = path.join(output_path, "release_data.json")
        self._links_output_file = path.join(output_path, "links.json")

        self._release_urls = {}  # format: {rating :  [list of urls], rating : [list of urls], ...}
        self._all_release_data = []

        self._saved = False  # has release data been saved?
        self._sleep_counter = 0  # has release data been saved?

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if not self._saved and len(self._all_release_data) > 0:
            self._save_release_data("w")

    # =================================================================================
    # PROPERTIES
    # =================================================================================

    @property
    def release_urls(self):
        """!
        @return  list of urls to be saved
        """
        return self._release_urls
    
    # =================================================================================
    # COLLECTION DATA
    # =================================================================================

    def scrape_and_save_collection_releases_url(self):
        """!
        @brief  scrape release urls from rym website, and save all relevant release urls
        """
        self._scrape_collection_releases_url()
        self._save_collection_releases_url()

    def load_collection_releases_url(self):
        """!
        @brief  load release urls from json (generated by previous use of program)
        """
        with open(self._links_output_file, "r") as f:
            data = f.read()
        self._release_urls = json.loads(data)

    def _scrape_collection_releases_url(self):
        """!
        @return  list of urls of all albums user has rated a specific rating
        Consider - adding a recovery feature and working with a temp file so you dont have to start from scratch in case of failure
        """
        print("loading releases in collection")
        for curr_rating in tqdm(arange(self._start_rating, self._end_rating + self.RATING_STEP, self.RATING_STEP)):
            current_urls = []
            for collection_url in self._generate_collection_urls(curr_rating):
                current_urls += self._parse_collections_page(collection_url)
                self._random_sleep(min_sleep=30, max_sleep=60)  # sleep between 0.5 and 5 minutes so as not to piss off rym gods
            self._release_urls[curr_rating] = current_urls

    def _save_collection_releases_url(self):
        with open(self._links_output_file, "w") as f:
            f.write(json.dumps(self._release_urls, indent=4))

    def _parse_collections_page(self, url: str):
        """!
        @param url  url of collection page to parse
        @return  list of release urls on recieved collection page
        """
        self._browser.get_url(url)
        page = CollectionPage(self._browser.get_soup())
        return page.release_urls

    def _generate_collection_urls(self, rating):
        """!
        @return  urls of collection of specific rating
        @example  rym.org/collection/r1.0/1, rym.org/collection/r1.0/2, ...
        """
        total_rating_pages = self._get_total_collection_pages(rating)
        for curr_page in range(1, total_rating_pages + 1):
            yield self.COLLECTION_PAGE_URL.format(self._username, rating, curr_page)

    def _get_total_collection_pages(self, rating):
        """!
        @param rating  rating to load collection of
        @return  amount of pages in collection of certain rating for a user
        """
        self._browser.get_url(self.COLLECTION_PAGE_URL.format(self._username, rating, 1))
        page = CollectionPage(self._browser.get_soup())
        return page.pages_in_collection

    # =================================================================================
    # RELEASE DATA
    # =================================================================================

    def scrape_and_save_release_data(self):
        self._scrape_release_data()
        self._save_release_data("w")

    def _scrape_release_data(self):
        for rating in self._release_urls:
            print("loading releases rated: {}".format(rating))
            for release_url in tqdm(self._release_urls[rating]):
                self._browser.get_url(release_url)
                try:
                    page = ReleasePage(self._browser.get_soup(), rating)
                    self._all_release_data.append(page.release_data)
                except Exception as e:
                    tqdm.write("error parsing release at url: {}".format(release_url))
                self._random_sleep(min_sleep=15, max_sleep=60) 

    def _save_release_data(self, mode):
        """
        @brief  cycle through saved release_data dataclasses and save release data to json
        """
        with ReleaseDataSaver(self._db_output_file, mode) as f:
            for release_data in self._all_release_data:
                f.write(release_data)
        self._saved = True

    # =================================================================================
    # Recovery Mode
    # =================================================================================

    def recover(self):
        """
        @brief  recover from failed download
        """
        self._get_remaining_links()
        self._scrape_release_data()
        self._save_release_data("a")
    
    def _get_remaining_links(self):
        """!
        @brief  set release_data to have all links not yet downloaded
        """
        with open(self._links_output_file, "r") as link_file, ReleaseDataSaver(self._db_output_file, "r") as data_file:
            links = json.loads(link_file.read())
            release_data = data_file.read()

        data_count = len(release_data)
        for rating in links:
            if len(links[rating]) > data_count:
                self.release_urls[rating] = links[rating][data_count:]
                data_count = 0
            else:
                data_count -= len(links[rating])
        

    # =================================================================================
    # OTHER
    # =================================================================================

    def _random_sleep(self, min_sleep=5, max_sleep=3600):
        random_sleep = randint(min_sleep, max_sleep)
        if self._sleep_counter % 250 == 0 and self._sleep_counter > 0:
            random_sleep = 3600  # occasionally sleep for an hour :P
        #tqdm.write("randomly sleeping for: {} seconds".format(random_sleep)) 
        time.sleep(random_sleep)
        self._sleep_counter += 1


